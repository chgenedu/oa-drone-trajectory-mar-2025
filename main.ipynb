{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcdcb3d0-62af-41df-9fad-fcb84f5af016",
   "metadata": {},
   "source": [
    "# Drone Trajectory Planner\n",
    "\n",
    "In this project, we will develop the drone trajectory planner. This notebook serves as the main file for the project, where we will refer to the instructions and demonstrate our code.\n",
    "\n",
    "Please follow week by week instructions, which includes writing the code in the `src/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83a63ad4-c249-484a-99e2-d9724aa5d41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the files and libraries required for the project\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import copy\n",
    "    \n",
    "import numpy as np\n",
    "\n",
    "from src.camera_utils import compute_image_footprint_on_surface, compute_ground_sampling_distance, project_world_point_to_image\n",
    "from src.data_model import Camera, DatasetSpec\n",
    "from src.plan_computation import compute_distance_between_images, compute_speed_during_photo_capture, generate_photo_plan_on_grid\n",
    "from src.visualization import plot_photo_plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44eb7f16-9094-4bc8-8ce7-065991ea0b78",
   "metadata": {},
   "source": [
    "# Week 1: Introduction\n",
    "\n",
    "No code contribution expected this week"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c08643e-1e37-4614-bc8f-b5636127b345",
   "metadata": {},
   "source": [
    "# Week 2: Camera System Modeling and Operations\n",
    "\n",
    "We plan to\n",
    "- Model the simple pinhole camera system\n",
    "- Write utility functions to\n",
    "    - project a 3D world point to an image\n",
    "    - Compute image footprint on a surface\n",
    "    - Compute the Ground Sampling Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65c8b8f-6f33-4cd4-8c3a-74acbdbd2c7d",
   "metadata": {},
   "source": [
    "## Model the camera parameters\n",
    "\n",
    "We want to model the following camera parameters in Python:\n",
    "- focal length along x axis (in pixels)\n",
    "- focal length along y axis (in pixels)\n",
    "- optical center of the image along the x axis (in pixels)\n",
    "- optical center of the image along the y axis (in pixels)\n",
    "- Size of the sensor along the x axis (in mm)\n",
    "- Size of the sensor along the y axis (in mm)\n",
    "- Number of pixels in the image along the x axis\n",
    "- Number of pixels in the image along the y axis\n",
    "\n",
    "I recommend to use `dataclasses` ([Python documentation](https://docs.python.org/3/library/dataclasses.html), [Blog](https://www.dataquest.io/blog/how-to-use-python-data-classes/) to model these parameters.\n",
    "\n",
    "$\\color{red}{\\text{TODO: }}$ Implement `Camera` in `src/data_model.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51f75a3f-b1b1-4087-b9ea-6d5b245ab0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for Skydio VT300L - Wide camera\n",
    "# Ref: https://support.skydio.com/hc/en-us/articles/20866347470491-Skydio-X10-camera-and-metadata-overview\n",
    "fx = 4938.56\n",
    "fy = 4936.49\n",
    "cx = 4095.5\n",
    "cy = 3071.5\n",
    "sensor_size_x_mm = 13.107 # single pixel size * number of pixels in X dimension\n",
    "sensor_size_y_mm = 9.830 # single pixel size * number of pixels in Y dimension\n",
    "image_size_x = 8192\n",
    "image_size_y = 6144\n",
    "\n",
    "camera_x10 = Camera(fx, fy, cx, cy, sensor_size_x_mm, sensor_size_y_mm, image_size_x, image_size_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0c3834b-6ae4-49b2-8a4f-9a50a08c2cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X10 camera model: Camera(fx=4938.56, fy=4936.49, cx=4095.5, cy=3071.5, sensor_size_x_mm=13.107, sensor_size_y_mm=9.83, image_size_x_px=8192, image_size_y_px=6144)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X10 camera model: {camera_x10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1db4d3-824e-49b9-af3a-dbeb3323625a",
   "metadata": {},
   "source": [
    "## Project 3D world points into the image\n",
    "\n",
    "\n",
    "![Camera Projection](assets/image_projection.png)\n",
    "Reference: [Robert Collins CSE483](https://www.cse.psu.edu/~rtc12/CSE486/lecture12.pdf)\n",
    "\n",
    "\n",
    "Equations to implement:\n",
    "$$ x = f_x \\frac{X}{Z} $$\n",
    "$$ y = f_y \\frac{Y}{Z} $$\n",
    "$$ u = x + c_x $$\n",
    "$$ v = y + c_y $$\n",
    "\n",
    "$\\color{red}{\\text{TODO: }}$ Implement function `project_world_point_to_image` in `src/camera_utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a3bd4c0-188b-4f95-98c9-95bb351e2d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 25. -30.  50.] projected to [6564.7803   109.60596]\n"
     ]
    }
   ],
   "source": [
    "point_3d = np.array([25, -30, 50], dtype=np.float32)\n",
    "expected_uv = np.array([6564.80, 109.60], dtype=np.float32)\n",
    "uv = project_world_point_to_image(camera_x10, point_3d)\n",
    "\n",
    "print(f\"{point_3d} projected to {uv}\")\n",
    "\n",
    "assert np.allclose(uv, expected_uv, atol=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf58acce-ca40-492d-9281-791c05c92776",
   "metadata": {},
   "source": [
    "## Compute Image Footprint on the surface\n",
    "\n",
    "We have written code to *project* a 3D point into the image. The reverse operation is reprojection, where we take $(x, y)$ and compute the $(X, Y)$ for a given value of $Z$. Note that while going from 3D to 2D, the depth becomes ambiguous so we need the to specify the $Z$.\n",
    "\n",
    "An image's footprint is the area on the surface which is captured by the image. We can take the two corners of the image and reproject them at a given distance to obtain the width and length of the image.\n",
    "\n",
    "$\\color{red}{\\text{TODO: }}$ Implement function `compute_image_footprint_on_surface` in `src/camera_utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d3e87ae-2123-4362-bf6e-279e6afb360c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Footprint at 100m = [165.87831271 124.46090238]\n"
     ]
    }
   ],
   "source": [
    "footprint_at_100m = compute_image_footprint_on_surface(camera_x10, 100)\n",
    "expected_footprint_at_100m = np.array([165.88, 124.46], dtype=np.float32)\n",
    "\n",
    "print(f\"Footprint at 100m = {footprint_at_100m}\")\n",
    "\n",
    "assert np.allclose(footprint_at_100m, expected_footprint_at_100m, atol=1e-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf7af93f-e95b-40e2-b607-39020015381b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Footprint at 200m = [331.75662541 248.92180476]\n"
     ]
    }
   ],
   "source": [
    "footprint_at_200m = compute_image_footprint_on_surface(camera_x10, 200)\n",
    "expected_footprint_at_200m = expected_footprint_at_100m * 2\n",
    "\n",
    "print(f\"Footprint at 200m = {footprint_at_200m}\")\n",
    "\n",
    "assert np.allclose(footprint_at_200m, expected_footprint_at_200m, atol=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84486ad6-a4c5-4e5a-ba40-ad125ced7d3d",
   "metadata": {},
   "source": [
    "## Ground Sampling Distance\n",
    "\n",
    "Ground sampling distance is the length of the ground (in m) captured by a single pixel. We have the image footpring (the dimensions of ground captured by the whole sensor, and the number of pixels along the horizontal and vertical dimension. Can we get GSD from these two quantities?\n",
    "\n",
    "Note: Please return just one value of the GSD. Take the mininum of the values along the two axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f21aa3d1-08be-4bce-8554-ec834ad000bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSD at 100m: 0.020248817469059807\n"
     ]
    }
   ],
   "source": [
    "gsd_at_100m = compute_ground_sampling_distance(camera_x10, 100)\n",
    "expected_gsd_at_100m = 0.0202\n",
    "\n",
    "print(f\"GSD at 100m: {gsd_at_100m}\")\n",
    "\n",
    "assert np.allclose(gsd_at_100m, expected_gsd_at_100m, atol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47477599-e78b-46d4-9cac-725bcbb5e6eb",
   "metadata": {},
   "source": [
    "## Bonus: Reprojection from 2D to 3D\n",
    "\n",
    "If we have a 2d pixel location of a point along with the camera model, can we go back to 3D?\n",
    "Do we need any additional information.\n",
    "\n",
    "\n",
    "$\\color{red}{\\text{TODO: }}$ Implement function `reproject_image_point_to_world` in `src/camera_utils.py` and demonstrate it by running it in the notebook. Confirm that your reprojection + projection function are consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ee043e1-3bbc-4f09-912a-f38ea9f9d394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 25. -30.  50.] projected to [6564.7803   109.60596]\n",
      "[6564.7803   109.60596] reprojected back to [ 25.00000381 -29.99999809  50.        ]\n",
      "original world point: [ 25. -30.  50.]\n",
      "recovered world point: [ 25.00000381 -29.99999809  50.        ]\n"
     ]
    }
   ],
   "source": [
    "# added by CH\n",
    "# Variables added by CH have suffix *_CH\n",
    "# Modifying and re-using test code (from above) for project_world_point_to_image().\n",
    "\n",
    "from src.camera_utils import reproject_image_point_to_world\n",
    "\n",
    "distance_to_surface_CH = 50 # distance to world point (in m)\n",
    "point_3d_CH = np.array([25, -30, distance_to_surface_CH], dtype=np.float32)\n",
    "expected_uv_CH = np.array([6564.80, 109.60], dtype=np.float32)\n",
    "uv_CH = project_world_point_to_image(camera_x10, point_3d)\n",
    "\n",
    "print(f\"{point_3d} projected to {uv_CH}\")\n",
    "assert np.allclose(uv_CH, expected_uv_CH, atol=1e-2)\n",
    "\n",
    "# recovering 3d point from image using the same distance\n",
    "recovered_point_3d_CH = reproject_image_point_to_world(camera_x10, distance_to_surface_CH, np.array([uv_CH[0], uv_CH[1]]))\n",
    "\n",
    "print(f\"{uv_CH} reprojected back to {recovered_point_3d_CH}\")\n",
    "print(f\"original world point: {point_3d_CH}\")\n",
    "print(f\"recovered world point: {recovered_point_3d_CH}\")\n",
    "assert np.allclose(recovered_point_3d_CH, point_3d_CH, atol=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59349449-f7ed-4e2f-aa80-17a2fabf51f1",
   "metadata": {},
   "source": [
    "# Week 3: Model the user requirements\n",
    "\n",
    "For this week, we will model the dataset specifications.\n",
    "\n",
    "- Overlap: the ratio (in 0 to 1) of scene shared between two consecutive images.\n",
    "- Sidelap: the ratio (in 0 to 1) of scene shared between two images in adjacent rows.\n",
    "- Height: the height of the scan above the ground (in meters).\n",
    "- Scan_dimension_x: the horizontal size of the rectangle to be scanned\n",
    "- Scan_dimension_y: the vertical size of the rectangle to be scanned\n",
    "- exposure_time_ms: the exposure time for each image (in milliseconds).\n",
    "\n",
    "\n",
    "$\\color{red}{\\text{TODO: }}$ Implement `DatasetSpec` in `src/data_model.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38206e65-458d-4d0d-b3fc-7e45039c0b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nominal specs: DatasetSpec(overlap=0.7, sidelap=0.7, height=30.48, scan_dimension_x=150, scan_dimension_y=150, exposure_time_ms=2)\n"
     ]
    }
   ],
   "source": [
    "# Model the nomimal dataset spec\n",
    "\n",
    "overlap = 0.7\n",
    "sidelap = 0.7\n",
    "height = 30.48 # 100 ft\n",
    "scan_dimension_x = 150\n",
    "scan_dimension_y = 150\n",
    "exposure_time_ms = 2 # 1/500 exposure time\n",
    "\n",
    "dataset_spec = DatasetSpec(overlap, sidelap, height, scan_dimension_x, scan_dimension_y, exposure_time_ms)\n",
    "\n",
    "print(f\"Nominal specs: {dataset_spec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135a5201-bcbc-4e57-9201-31d3dbb50005",
   "metadata": {},
   "source": [
    "# Week 4: Compute Distance Between Photos\n",
    "\n",
    "The overlap and sidelap are the ratio of the dimensions shared between two photos. We already know the footprint of a single image at a given distance. Can we convert the ratio into actual distances? And how does the distance on the surface relate to distance travelled by the camera?\n",
    "\n",
    "$\\color{red}{\\text{TODO: }}$ Implement `compute_distance_between_images` in `src/plan_computation.py`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70b32a91-2577-46ec-bb07-9a0a5fd01243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed distance for X10 camera with nominal dataset specs: [15.16791291 11.38070491]\n"
     ]
    }
   ],
   "source": [
    "computed_distances = compute_distance_between_images(camera_x10, dataset_spec)\n",
    "expected_distances = np.array([15.17, 11.38], dtype=np.float32)\n",
    "\n",
    "print(f\"Computed distance for X10 camera with nominal dataset specs: {computed_distances}\")\n",
    "\n",
    "assert np.allclose(computed_distances, expected_distances, atol=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5474e7ac-28bb-4ab3-ad8d-cb5398d5696b",
   "metadata": {},
   "source": [
    "$\\color{red}{\\text{TODO: }}$ define more specifications/camera parameters and check the computed distances. Does that align with your expections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7f9334a-6ee1-4aa4-8770-d0f48b36f18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We double the height. We expected the computed distance to double.\n",
      "Computed distance at height 30.48: [15.16791291 11.38070491]\n",
      "Expected distance at height 30.48: [15.17 11.38]\n",
      "Computed distance at height 60.96: [30.33582583 22.76140983]\n",
      "Expected distance at height 60.96: [30.34 22.76]\n"
     ]
    }
   ],
   "source": [
    "# Additional checks 1: Double the height, expect distance to double.\n",
    "camera_ = copy.copy(camera_x10)\n",
    "dataset_spec_ = copy.copy(dataset_spec)\n",
    "expected_distances_ = copy.copy(expected_distances)\n",
    "\n",
    "# Double the height. We expect the computed distance to double.\n",
    "print(f\"We double the height. We expected the computed distance to double.\")\n",
    "dataset_spec_.height = 2 * dataset_spec.height\n",
    "\n",
    "computed_distances_ = compute_distance_between_images(camera_, dataset_spec_)\n",
    "expected_distances_ = 2 * expected_distances_\n",
    "\n",
    "print(f\"Computed distance at height {dataset_spec.height}: {computed_distances}\")\n",
    "print(f\"Expected distance at height {dataset_spec.height}: {expected_distances}\")\n",
    "print(f\"Computed distance at height {dataset_spec_.height}: {computed_distances_}\")\n",
    "print(f\"Expected distance at height {dataset_spec_.height}: {expected_distances_}\")\n",
    "assert np.allclose(computed_distances_, expected_distances_, atol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e258fcdd-0e49-417c-9729-ec273d1b6ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduce overlap from 0.7 to 0.4, which is the same as changing the non-overlap ratio from 0.3 to 0.6.\n",
      "We expect the distance traveled in the horizontal direction to double.\n",
      "Computed distance with overlap 0.7: [15.16791291 11.38070491]\n",
      "Expected distance with overlap 0.7: [15.17 11.38]\n",
      "Computed distance at overlap 0.4: [30.33582583 11.38070491]\n",
      "Expected distance at overlap 0.4: [30.34 11.38]\n"
     ]
    }
   ],
   "source": [
    "# Additional checks 2: Reduce the overlap, expect the distance to increase.\n",
    "camera_ = copy.copy(camera_x10)\n",
    "dataset_spec_ = copy.copy(dataset_spec)\n",
    "expected_distances_ = copy.copy(expected_distances)\n",
    "\n",
    "print(f\"Reduce overlap from 0.7 to 0.4, which is the same as changing the non-overlap ratio from 0.3 to 0.6.\")\n",
    "print(f\"We expect the distance traveled in the horizontal direction to double.\")\n",
    "dataset_spec_.overlap = 0.4\n",
    "\n",
    "computed_distances_ = compute_distance_between_images(camera_, dataset_spec_)\n",
    "\n",
    "# We expect the horizontal distance to double, but vertical distance to be unchanged.\n",
    "expected_distances_[0] = 2 * expected_distances_[0]\n",
    "\n",
    "print(f\"Computed distance with overlap {dataset_spec.overlap}: {computed_distances}\")\n",
    "print(f\"Expected distance with overlap {dataset_spec.overlap}: {expected_distances}\")\n",
    "print(f\"Computed distance at overlap {dataset_spec_.overlap}: {computed_distances_}\")\n",
    "print(f\"Expected distance at overlap {dataset_spec_.overlap}: {expected_distances_}\")\n",
    "assert np.allclose(computed_distances_, expected_distances_, atol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fdfd017-e51e-41d6-9473-3e603c044d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduce sidelap from 0.7 to 0.4, which is the same as changing the non-sidelap ratio from 0.3 to 0.6.\n",
      "We expect the distance traveled in the veritical direction to double.\n",
      "Computed distance with sidelap 0.7: [15.16791291 11.38070491]\n",
      "Expected distance with overlap 0.7: [15.17 11.38]\n",
      "Computed distance with sidelap 0.4: [15.16791291 22.76140983]\n",
      "Expected distance with sidelap 0.4: [15.17 22.76]\n"
     ]
    }
   ],
   "source": [
    "# Additional checks 3: Reduce the sidelap, expect the distance to increase.\n",
    "camera_ = copy.copy(camera_x10)\n",
    "dataset_spec_ = copy.copy(dataset_spec)\n",
    "expected_distances_ = copy.copy(expected_distances)\n",
    "\n",
    "print(f\"Reduce sidelap from 0.7 to 0.4, which is the same as changing the non-sidelap ratio from 0.3 to 0.6.\")\n",
    "print(f\"We expect the distance traveled in the veritical direction to double.\")\n",
    "dataset_spec_.sidelap = 0.4\n",
    "\n",
    "computed_distances_ = compute_distance_between_images(camera_, dataset_spec_)\n",
    "\n",
    "# We expect the vertical distance to double, but horizontal distance to be unchanged.\n",
    "expected_distances_[1] = 2 * expected_distances[1]\n",
    "\n",
    "print(f\"Computed distance with sidelap {dataset_spec.sidelap}: {computed_distances}\")\n",
    "print(f\"Expected distance with overlap {dataset_spec.overlap}: {expected_distances}\")\n",
    "print(f\"Computed distance with sidelap {dataset_spec_.sidelap}: {computed_distances_}\")\n",
    "print(f\"Expected distance with sidelap {dataset_spec_.sidelap}: {expected_distances_}\")\n",
    "assert np.allclose(computed_distances_, expected_distances_, atol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f30d43a9-2d55-48be-98d9-d9cf2066645e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divide the focal length fx and fy by 2.\n",
      "We expect the distance traveled in the horizontal direction and vertical direction to double.\n",
      "Computed distance with focal lengths 4938.56 4936.49: [15.16791291 11.38070491]\n",
      "Expected distance with focal lengths 4938.56 4936.49: [15.17 11.38]\n",
      "Computed distance with focal lengths 2469.28 2468.245: [30.33582583 22.76140983]\n",
      "Expected distance with focal lengths 2469.28 2468.245: [30.34 22.76]\n"
     ]
    }
   ],
   "source": [
    "# Additional checks 4: Half the focal length fx and fy. Expect distance traveled to double.\n",
    "# Rearranging the Perspective Projection Equation x = fx*X/Z to X = x*Z/fx,\n",
    "# so we expect that if we cut fx to half of its original value, \n",
    "# then X, and therefore the horizontal distance traveled, would double.\n",
    "# The effect of halving the focal length fy is the same, except it is for the vertical direction.\n",
    "\n",
    "camera_ = copy.copy(camera_x10)\n",
    "dataset_spec_ = copy.copy(dataset_spec)\n",
    "expected_distances_ = copy.copy(expected_distances)\n",
    "\n",
    "print(f\"Divide the focal length fx and fy by 2.\")\n",
    "print(f\"We expect the distance traveled in the horizontal direction and vertical direction to double.\")\n",
    "camera_.fx = camera_.fx / 2\n",
    "camera_.fy = camera_.fy / 2\n",
    "\n",
    "computed_distances_ = compute_distance_between_images(camera_, dataset_spec_)\n",
    "\n",
    "# We expect the vertical distance to double, but horizontal distance to be unchanged.\n",
    "expected_distances_ = 2 * expected_distances_\n",
    "\n",
    "print(f\"Computed distance with focal lengths {camera_x10.fx} {camera_x10.fy}: {computed_distances}\")\n",
    "print(f\"Expected distance with focal lengths {camera_x10.fx} {camera_x10.fy}: {expected_distances}\")\n",
    "print(f\"Computed distance with focal lengths {camera_.fx} {camera_.fy}: {computed_distances_}\")\n",
    "print(f\"Expected distance with focal lengths {camera_.fx} {camera_.fy}: {expected_distances_}\")\n",
    "assert np.allclose(computed_distances_, expected_distances_, atol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4414b8d4-cf32-404e-85b2-ec05439ecd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed distance: [15.16791291 11.38070491]\n"
     ]
    }
   ],
   "source": [
    "# unused template\n",
    "camera_ = copy.copy(camera_x10)\n",
    "dataset_spec_ = copy.copy(dataset_spec)\n",
    "\n",
    "computed_distances_ = compute_distance_between_images(camera_, dataset_spec_)\n",
    "print(f\"Computed distance: {computed_distances_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea6d39a-89af-42bc-bb63-2d22380dec1f",
   "metadata": {},
   "source": [
    "## Bonus: Non-Nadir photos\n",
    "\n",
    "We have solved for the distance assuming that the camera is facing straight down to the ground. This is called [Nadir scanning](https://support.esri.com/en-us/gis-dictionary/nadir). However, in practise we might want a custom gimbal angle.\n",
    "\n",
    "Your bonus task is to make the distance computation general. Introduce a double `camera_angle` parameter (which is the angle from the X-axis) in the dataset specification, and work out how to adapt your computation. Feel free to reach out to Ayush to discuss ideas and assumptions!\n",
    "\n",
    "![Non Nadir Footprint](assets/non_nadir_gimbal_angle.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b38c8af-8b36-47ce-b092-f7dcd3dd988b",
   "metadata": {},
   "source": [
    "## Bonus work by CH\n",
    "The new function written is `compute_distance_between_images_with_angle(camera: Camera, dataset_spec: DatasetSpec, angle_deg_x: float, angle_deg_y: float)`.\n",
    "                                               \n",
    "In the function compute_distance_between_images_with_angle(), we added two additional angles, for the camera angles from the x and y axes. \n",
    "For the test code below, we are only testing the angle in x, so we set the y angle to 0.\n",
    "\n",
    "The following is the calculation for the footprint in the x direction. \n",
    "\n",
    "Assumptions:\n",
    "* For the angle in each direction, FOV/2 + abs(camera_angle) < 90 degrees, otherwise an edge of the FOV will be at or above the horizon. (FOV = Field of View)\n",
    "* The only adjustment for the distance calculation is the footprint. We do not need to make adjustment for the overlap or sidelap.\n",
    "\n",
    "If camera_angle >= 0, We have two cases:\n",
    "* If camera_angle >= FOV/2, then `footprint = (tan(camera_angle + FOV/2) - tan(camera_angle - FOV/2)) * height`\n",
    "* If 0 <= camera_angle < FOV/2, then `footprint = (tan(camera_angle + FOV/2) + tan(FOV/2 - camera_angle)) * height`\n",
    "![camera angle 1](assets/CH_assets/CH_camera_angle_1.png) ![camera angle 2](assets/CH_assets/CH_camera_angle_2.png)\n",
    "\n",
    "If camera angle < 0, we still get the same equations since tan() is an odd function.\n",
    "\n",
    "Then we use https://www.wolframalpha.com/ to simplify these functions and we found out that\n",
    "both of them can be simplified to the same form, regardless of whether\n",
    "the camera_angle is greater than FOV/2:\n",
    "\n",
    "`footprint = 2 * sin(FOV) / (cos(FOV) + cos(2*camera_angle))`\n",
    "\n",
    "The above formula was used to calculate the modified footprint for x and for y.\n",
    "Lastly, we multiply the footprint by (1-overlap) or by (1-sidelap) to get the distance required.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a52868a-b70c-4468-b3cb-53504b32b6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field of View FOV(degrees) 79.34405165142869, 63.78838119894017\n",
      "\n",
      "Camera_angle_x(deg)\tSum of fov_deg_x/2 + abs(camera_angle_x)\t Computed distance for X10 camera\n",
      "  -50\t\t\t89.67202582571434\t\t\t\t[1595.736505901222\t11.380704913815286]\n",
      "  -48\t\t\t87.67202582571434\t\t\t\t[223.58848617448598\t11.380704913815286]\n",
      "  -46\t\t\t85.67202582571434\t\t\t\t[119.80826703492599\t11.380704913815286]\n",
      "  -44\t\t\t83.67202582571434\t\t\t\t[81.7641634341542\t11.380704913815286]\n",
      "  -42\t\t\t81.67202582571434\t\t\t\t[62.09458376234165\t11.380704913815286]\n",
      "  -40\t\t\t79.67202582571434\t\t\t\t[50.12456827416916\t11.380704913815286]\n",
      "  -38\t\t\t77.67202582571434\t\t\t\t[42.10693418089635\t11.380704913815286]\n",
      "  -36\t\t\t75.67202582571434\t\t\t\t[36.38713601325202\t11.380704913815286]\n",
      "  -34\t\t\t73.67202582571434\t\t\t\t[32.12164492175725\t11.380704913815286]\n",
      "  -32\t\t\t71.67202582571434\t\t\t\t[28.83545730656419\t11.380704913815286]\n",
      "  -30\t\t\t69.67202582571434\t\t\t\t[26.240819533127922\t11.380704913815286]\n",
      "  -28\t\t\t67.67202582571434\t\t\t\t[24.153382390884456\t11.380704913815286]\n",
      "  -26\t\t\t65.67202582571434\t\t\t\t[22.44971793715816\t11.380704913815286]\n",
      "  -24\t\t\t63.67202582571434\t\t\t\t[21.044204686503942\t11.380704913815286]\n",
      "  -22\t\t\t61.67202582571434\t\t\t\t[19.875709774830803\t11.380704913815286]\n",
      "  -20\t\t\t59.67202582571434\t\t\t\t[18.899546431527632\t11.380704913815286]\n",
      "  -18\t\t\t57.67202582571434\t\t\t\t[18.082423194150905\t11.380704913815286]\n",
      "  -16\t\t\t55.67202582571434\t\t\t\t[17.39916589332319\t11.380704913815286]\n",
      "  -14\t\t\t53.67202582571434\t\t\t\t[16.83053059837447\t11.380704913815286]\n",
      "  -12\t\t\t51.67202582571434\t\t\t\t[16.361710685383585\t11.380704913815286]\n",
      "  -10\t\t\t49.67202582571434\t\t\t\t[15.981299063569413\t11.380704913815286]\n",
      "   -8\t\t\t47.67202582571434\t\t\t\t[15.680557458921477\t11.380704913815286]\n",
      "   -6\t\t\t45.67202582571434\t\t\t\t[15.452898782492758\t11.380704913815286]\n",
      "   -4\t\t\t43.67202582571434\t\t\t\t[15.293521920546006\t11.380704913815286]\n",
      "   -2\t\t\t41.67202582571434\t\t\t\t[15.199159468256227\t11.380704913815286]\n",
      "    0\t\t\t39.67202582571434\t\t\t\t[15.167912913885836\t11.380704913815286]\n",
      "    2\t\t\t41.67202582571434\t\t\t\t[15.199159468256227\t11.380704913815286]\n",
      "    4\t\t\t43.67202582571434\t\t\t\t[15.293521920546006\t11.380704913815286]\n",
      "    6\t\t\t45.67202582571434\t\t\t\t[15.452898782492758\t11.380704913815286]\n",
      "    8\t\t\t47.67202582571434\t\t\t\t[15.680557458921477\t11.380704913815286]\n",
      "   10\t\t\t49.67202582571434\t\t\t\t[15.981299063569413\t11.380704913815286]\n",
      "   12\t\t\t51.67202582571434\t\t\t\t[16.361710685383585\t11.380704913815286]\n",
      "   14\t\t\t53.67202582571434\t\t\t\t[16.83053059837447\t11.380704913815286]\n",
      "   16\t\t\t55.67202582571434\t\t\t\t[17.39916589332319\t11.380704913815286]\n",
      "   18\t\t\t57.67202582571434\t\t\t\t[18.082423194150905\t11.380704913815286]\n",
      "   20\t\t\t59.67202582571434\t\t\t\t[18.899546431527632\t11.380704913815286]\n",
      "   22\t\t\t61.67202582571434\t\t\t\t[19.875709774830803\t11.380704913815286]\n",
      "   24\t\t\t63.67202582571434\t\t\t\t[21.044204686503942\t11.380704913815286]\n",
      "   26\t\t\t65.67202582571434\t\t\t\t[22.44971793715816\t11.380704913815286]\n",
      "   28\t\t\t67.67202582571434\t\t\t\t[24.153382390884456\t11.380704913815286]\n",
      "   30\t\t\t69.67202582571434\t\t\t\t[26.240819533127922\t11.380704913815286]\n",
      "   32\t\t\t71.67202582571434\t\t\t\t[28.83545730656419\t11.380704913815286]\n",
      "   34\t\t\t73.67202582571434\t\t\t\t[32.12164492175725\t11.380704913815286]\n",
      "   36\t\t\t75.67202582571434\t\t\t\t[36.38713601325202\t11.380704913815286]\n",
      "   38\t\t\t77.67202582571434\t\t\t\t[42.10693418089635\t11.380704913815286]\n",
      "   40\t\t\t79.67202582571434\t\t\t\t[50.12456827416916\t11.380704913815286]\n",
      "   42\t\t\t81.67202582571434\t\t\t\t[62.09458376234165\t11.380704913815286]\n",
      "   44\t\t\t83.67202582571434\t\t\t\t[81.7641634341542\t11.380704913815286]\n",
      "   46\t\t\t85.67202582571434\t\t\t\t[119.80826703492599\t11.380704913815286]\n",
      "   48\t\t\t87.67202582571434\t\t\t\t[223.58848617448598\t11.380704913815286]\n",
      "   50\t\t\t89.67202582571434\t\t\t\t[1595.736505901222\t11.380704913815286]\n"
     ]
    }
   ],
   "source": [
    "from src.plan_computation import compute_distance_between_images_with_angle, fov\n",
    "[fov_deg_x, fov_deg_y] = fov(camera_x10)\n",
    "print(f\"Field of View FOV(degrees) {fov_deg_x}, {fov_deg_y}\\n\")\n",
    "\n",
    "print(f\"Camera_angle_x(deg)\\tSum of fov_deg_x/2 + abs(camera_angle_x)\\t Computed distance for X10 camera\")\n",
    "for deg in range(-50,51, 2):\n",
    "    computed_distances = compute_distance_between_images_with_angle(camera_x10, dataset_spec, deg, 0)\n",
    "    expected_distances = np.array([15.17, 11.38], dtype=np.float32) # for camera angle = 0 degrees\n",
    "    print(f\"{deg:>5}\\t\\t\\t{fov_deg_x/2 + abs(deg)}\\t\\t\\t\\t[{computed_distances[0]}\\t{computed_distances[1]}]\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfc13a5-d13d-4930-a47b-2851e5458ceb",
   "metadata": {},
   "source": [
    "# Week 5: Compute Maximum Speed For Blur Free Photos\n",
    "\n",
    "To restrict motion blur due to camera movement to tolerable limits, we need to restrict the speed such that the image contents move less than 1px away. \n",
    "\n",
    "How much does 1px of movement translate to movement of the scene on the ground? It is the ground sampling distance!\n",
    "From previous week, we know that this is the maximum movement the camera can have. \n",
    "We have the distance now. To get speed we need to divide it with time. Do we have time already in our data models?\n",
    "\n",
    "$\\color{red}{\\text{TODO: }}$ Implement `compute_speed_during_photo_capture` in `src/plan_computation.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1292957c-d66f-4ac9-bb6f-1dc783d1a5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_speed = compute_speed_during_photo_capture(camera_x10, dataset_spec, allowed_movement_px=1)\n",
    "expected_speed = 3.09\n",
    "\n",
    "print(f\"Computed speed during photo captures: {computed_speed:.2f}\")\n",
    "\n",
    "assert np.allclose(computed_speed, expected_speed, atol=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fe63d9-c416-4bbf-b0ce-8c678de681de",
   "metadata": {},
   "source": [
    "$\\color{red}{\\text{TODO: }}$ define more specifications/camera parameters and check the computed distances. Does that align with your expections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85212946-83d0-475c-9740-e04d10a1ec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_ = copy.copy(camera_x10)\n",
    "dataset_spec_ = copy.copy(dataset_spec)\n",
    "\n",
    "computed_speed_ = compute_speed_during_photo_capture(camera_, dataset_spec_)\n",
    "print(f\"Computed distance: {computed_speed_:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d7075d-f520-43bd-8b8b-b36e9c6a6bc2",
   "metadata": {},
   "source": [
    "# Week 6: Generate Full Flight Plans  \n",
    "\n",
    "We now have all the tools to generate the full flight plan.\n",
    "\n",
    "Steps for this week:\n",
    "1. Define the `Waypoint` data model. What attributes should the data model have?\n",
    "   1. For Nadir scans, just the position of the camera is enough as we will always look drown to the ground.\n",
    "   2. For general case (bonus), we also need to define where the drone will look at.\n",
    "3. Implement the function `generate_photo_plan_on_grid` to generate the full plan.\n",
    "   1. Compute the maximum distance between two images, horizontally and vertically.\n",
    "   2. Layer the images such that we cover the whole scan area. Note that you need to take care when the scan dimension is not a multiple of distance between images. Example: to cover 45m length with 10m between images, we would need 4.5 images. Not possible. 4 images would not satisfy the overlap, so we should go with 5. How should we arrange 5 images in the given 45m.\n",
    "   3. Assign the speed to each waypoint.\n",
    "\n",
    "$\\color{red}{\\text{TODO: }}$ Implement:\n",
    "- `Waypoint` in `src/data_model.py`\n",
    "- `generate_photo_plan_on_grid` in `src/plan_computation.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1e5c3e-9974-4f50-9413-1b9c5b523051",
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_plan = generate_photo_plan_on_grid(camera_x10, dataset_spec) \n",
    "\n",
    "print(f\"Computed plan with {len(computed_plan)} waypoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f3bf15-c584-44da-a789-c821acb3f9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUM_WAYPOINTS_TO_PRINT = 20\n",
    "\n",
    "for idx, waypoint in enumerate(computed_plan[:20]):\n",
    "    print(f\"Idx {idx}: {waypoint}\")\n",
    "if len(computed_plan) >= MAX_NUM_WAYPOINTS_TO_PRINT:\n",
    "    print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5544587f-fff7-406a-be65-ad99c7217e51",
   "metadata": {},
   "source": [
    "## Bonus: Time computation \n",
    "\n",
    "if you have some time, you can implement a time computation function. We can make the drone fly as fast as possible between photos, but make sure it can decelerate back to the required speed at the photos. Please use the following data: \n",
    "- Max drone speed: 16m/s.\n",
    "- Max acceleration: 3.5 m/s^2.\n",
    "\n",
    "Hint: you might need to use a trapezoidal speed profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a326c0e-86ff-443d-98ee-7a4fae0bfe81",
   "metadata": {},
   "source": [
    "# Week 7: Visualize Flight Plans\n",
    "\n",
    "This week, we will use a third party plotting framework called [Plotly](https://plotly.com/python/) to visualize our plans. Please follow this [tutorial](https://www.kaggle.com/code/kanncaa1/plotly-tutorial-for-beginners) to gain some basic experience with Plotly, and then come up with your own visualization function. You are free to choose to come up with your own visualization, and use something other than Plotly.\n",
    "\n",
    "$\\color{red}{\\text{TODO: }}$ Implement `plot_photo_plan` in `src/visualization.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3996504a-28fc-48f1-8094-94d9a6bd58f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_photo_plan(computed_plan)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ff5833-f107-4332-974c-b9294e02a1da",
   "metadata": {},
   "source": [
    "$\\color{red}{\\text{TODO: }}$ Compute the following ablations (and any other you can think of). \n",
    "You need to describe the input params you are changing, what impact you can observe, explanation behind the change in output, and practical implication of the correlation.\n",
    "\n",
    "1. Change overlap and confirm it affects the consecutive images\n",
    "2. Change sidelap and confirm it does not affect the consecutive images\n",
    "3. Change the height of the scan and document the affect on scan plans\n",
    "4. Change exposure time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbe090a-b696-4800-8373-6f4b3be02a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_ = copy.deepcopy(camera_x10)\n",
    "dataset_spec_ = copy.deepcopy(dataset_spec)\n",
    "\n",
    "dataset_spec_.exposure_time_ms = 1000\n",
    "\n",
    "print(camera_, dataset_spec_)\n",
    "\n",
    "fig = plot_photo_plan(generate_photo_plan_on_grid(camera_, dataset_spec_))\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
